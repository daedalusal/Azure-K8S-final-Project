---
- name: Basic setup for Kubernetes nodes
  hosts: all
  become: yes
  become_method: sudo
  become_user: root

  tasks:
    - name: Update apt cache
      apt:
        update_cache: yes

    - name: Install required packages
      apt:
        name:
          - curl
          - apt-transport-https
          - ca-certificates
          - gpg
        state: present

    - name: Set hostname for master
      hostname:
        name: k8s-master
      when: "'master' in group_names"

    - name: Set hostname for workers
      hostname:
        name: "k8s-worker-{{ inventory_hostname }}"
      when: "'workers' in group_names"

    - name: Disable swap
      command: swapoff -a

    - name: Remove swap entry from /etc/fstab
      replace:
        path: /etc/fstab
        regexp: '^([^#].*?\sswap\s.*)$'
        replace: '# \1'

    - name: Create keyrings directory for Kubernetes
      file:
        path: /etc/apt/keyrings
        state: directory
        mode: '0755'

    - name: Download Kubernetes APT key (stable version)
      shell: |
        curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.30/deb/Release.key | gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
      args:
        creates: /etc/apt/keyrings/kubernetes-apt-keyring.gpg

    - name: Add Kubernetes APT repository (stable version)
      apt_repository:
        repo: "deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.30/deb/ /"
        state: present
        filename: kubernetes.list

    - name: Install Kubernetes components
      apt:
        name:
          - kubelet
          - kubeadm
          - kubectl
        state: present
        update_cache: yes

    - name: Hold kubelet at current version
      dpkg_selections:
        name: kubelet
        selection: hold

    - name: Hold kubeadm at current version
      dpkg_selections:
        name: kubeadm
        selection: hold

    - name: Hold kubectl at current version
      dpkg_selections:
        name: kubectl
        selection: hold

    - name: Create keyrings directory for Helm
      file:
        path: /etc/apt/keyrings
        state: directory
        mode: '0755'

    - name: Download Helm GPG key and add to keyring
      shell: |
        curl -fsSL https://packages.buildkite.com/helm-linux/helm-debian/gpgkey | gpg --dearmor | tee /usr/share/keyrings/helm.gpg > /dev/null
      args:
        creates: /usr/share/keyrings/helm.gpg

    - name: Add Helm apt repository
      apt_repository:
        repo: "deb [signed-by=/usr/share/keyrings/helm.gpg] https://packages.buildkite.com/helm-linux/helm-debian/any/ any main"
        state: present
        filename: helm-stable-debian.list

    - name: Update apt cache after adding Helm repo
      apt:
        update_cache: yes

    - name: Install Helm
      apt:
        name: helm
        state: present

    - name: Install containerd
      apt:
        name: containerd
        state: present

    - name: Configure containerd
      shell: |
        mkdir -p /etc/containerd
        containerd config default | tee /etc/containerd/config.toml
      args:
        creates: /etc/containerd/config.toml

    - name: Configure containerd to use systemd cgroup driver
      replace:
        path: /etc/containerd/config.toml
        regexp: 'SystemdCgroup = false'
        replace: 'SystemdCgroup = true'

    - name: Restart containerd
      service:
        name: containerd
        state: restarted
        enabled: yes

    - name: Enable net.ipv4.ip_forward
      sysctl:
        name: net.ipv4.ip_forward
        value: '1'
        state: present
        reload: yes

    - name: Load bridge netfilter module
      modprobe:
        name: br_netfilter
        state: present

    - name: Ensure br_netfilter module loads on boot
      lineinfile:
        path: /etc/modules-load.d/k8s.conf
        line: br_netfilter
        create: yes

    - name: Load overlay module for containerd
      modprobe:
        name: overlay
        state: present

    - name: Ensure overlay module loads on boot
      lineinfile:
        path: /etc/modules-load.d/k8s.conf
        line: overlay
        create: yes

    - name: Create sysctl configuration file for Kubernetes
      copy:
        content: |
          net.bridge.bridge-nf-call-iptables  = 1
          net.bridge.bridge-nf-call-ip6tables = 1
          net.ipv4.ip_forward                 = 1
          net.ipv4.conf.all.forwarding        = 1
          net.ipv6.conf.all.forwarding        = 1
        dest: /etc/sysctl.d/k8s.conf
        mode: '0644'

    - name: Apply sysctl settings from k8s.conf
      command: sysctl --system

    - name: Ensure systemd-resolved is configured properly
      lineinfile:
        path: /etc/systemd/resolved.conf
        regexp: '^#?DNS='
        line: 'DNS=168.63.129.16 8.8.8.8'
        state: present
      notify: restart systemd-resolved

    - name: Ensure systemd-resolved fallback DNS
      lineinfile:
        path: /etc/systemd/resolved.conf
        regexp: '^#?FallbackDNS='
        line: 'FallbackDNS=1.1.1.1 8.8.4.4'
        state: present
      notify: restart systemd-resolved

  handlers:
    - name: restart systemd-resolved
      service:
        name: systemd-resolved
        state: restarted

- name: Initialize Kubernetes master and install Calico
  hosts: master
  become: yes
  tasks:
    - name: Initialize the Kubernetes cluster using kubeadm
      command: kubeadm init --pod-network-cidr=192.168.0.0/16
      args:
        creates: /etc/kubernetes/admin.conf
      register: kubeadm_init

    - name: Set up kubeconfig for azureuser
      shell: |
        mkdir -p /home/azureuser/.kube
        cp -f /etc/kubernetes/admin.conf /home/azureuser/.kube/config
        chown azureuser:azureuser /home/azureuser/.kube/config
      args:
        executable: /bin/bash

    - name: Install Calico network plugin
      shell: |
        kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml
      environment:
        KUBECONFIG: /home/azureuser/.kube/config

    - name: Wait for Calico to be ready
      shell: |
        kubectl wait --for=condition=Ready pod -l k8s-app=calico-node -n kube-system --timeout=300s
      environment:
        KUBECONFIG: /home/azureuser/.kube/config
      register: calico_ready
      retries: 5
      delay: 30
      until: calico_ready.rc == 0

    - name: Wait for Calico API resources to be available
      shell: |
        kubectl get crd felixconfigurations.crd.projectcalico.org
      environment:
        KUBECONFIG: /home/azureuser/.kube/config
      register: felix_crd_check
      retries: 10
      delay: 15
      until: felix_crd_check.rc == 0

    - name: Create default FelixConfiguration if it doesn't exist
      shell: |
        kubectl get felixconfiguration default >/dev/null 2>&1 || kubectl apply -f - <<EOF
        apiVersion: crd.projectcalico.org/v1
        kind: FelixConfiguration
        metadata:
          name: default
        spec:
          natOutgoingEnabled: true
        EOF
      environment:
        KUBECONFIG: /home/azureuser/.kube/config
      register: felix_create
      changed_when: felix_create.stdout.find('created') != -1

    - name: Enable Calico outbound NAT for pod traffic
      shell: |
        kubectl patch felixconfiguration default --type='merge' -p '{"spec":{"natOutgoingEnabled":true}}'
      environment:
        KUBECONFIG: /home/azureuser/.kube/config
      register: calico_nat
      changed_when: calico_nat.rc == 0
      retries: 3
      delay: 10

    - name: Check if default IP pool exists
      shell: |
        kubectl get ippool default-ipv4-ippool || echo "not found"
      environment:
        KUBECONFIG: /home/azureuser/.kube/config
      register: ippool_check
      ignore_errors: yes

    - name: Configure Calico IP pool for Azure
      shell: |
        if [[ "{{ ippool_check.stdout }}" == *"not found"* ]]; then
          kubectl apply -f - <<EOF
        apiVersion: crd.projectcalico.org/v1
        kind: IPPool
        metadata:
          name: default-ipv4-ippool
        spec:
          cidr: 192.168.0.0/16
          ipipMode: Always
          natOutgoing: true
          nodeSelector: all()
        EOF
        else
          kubectl patch ippool default-ipv4-ippool --type='merge' -p '{"spec":{"natOutgoing":true}}'
        fi
      environment:
        KUBECONFIG: /home/azureuser/.kube/config
      register: calico_ippool
      ignore_errors: yes

    - name: Restart Calico pods to apply configuration
      shell: |
        kubectl delete pods -n kube-system -l k8s-app=calico-node
        kubectl delete pods -n kube-system -l k8s-app=calico-kube-controllers
      environment:
        KUBECONFIG: /home/azureuser/.kube/config
      when: calico_nat.changed or calico_ippool.changed

    - name: Patch CoreDNS to use Azure DNS with fallback
      shell: |
        cat <<EOF | kubectl apply -f -
        apiVersion: v1
        kind: ConfigMap
        metadata:
          name: coredns
          namespace: kube-system
        data:
          Corefile: |
            .:53 {
                errors
                health {
                   lameduck 5s
                }
                ready
                kubernetes cluster.local in-addr.arpa ip6.arpa {
                   pods insecure
                   fallthrough in-addr.arpa ip6.arpa
                   ttl 30
                }
                prometheus :9153
                forward . 168.63.129.16 8.8.8.8 1.1.1.1 {
                   max_concurrent 1000
                   policy sequential
                   health_check 5s
                }
                cache 30 {
                   disable success cluster.local
                   disable denial cluster.local
                }
                loop
                reload
                loadbalance
            }
        EOF
      environment:
        KUBECONFIG: /home/azureuser/.kube/config

    - name: Create jenkins namespace
      shell: |
        kubectl create namespace jenkins || true
      environment:
        KUBECONFIG: /home/azureuser/.kube/config
      ignore_errors: yes

    - name: Remove all NetworkPolicies for learning environment
      shell: |
        # Remove any existing NetworkPolicies that might block communication
        kubectl delete networkpolicy --all --all-namespaces || true
      environment:
        KUBECONFIG: /home/azureuser/.kube/config
      ignore_errors: yes

    - name: Restart CoreDNS
      shell: kubectl rollout restart deployment coredns -n kube-system
      environment:
        KUBECONFIG: /home/azureuser/.kube/config

    - name: Verify cluster status after setup
      shell: |
        echo "=== Cluster Info ==="
        kubectl cluster-info
        echo "=== Node Status ==="
        kubectl get nodes -o wide
        echo "=== Pod Status ==="
        kubectl get pods --all-namespaces
        echo "=== DNS Test ==="
        kubectl run dns-test --image=busybox:1.28 --rm -it --restart=Never --command -- nslookup kubernetes.default || true
      environment:
        KUBECONFIG: /home/azureuser/.kube/config
      register: cluster_status
      ignore_errors: yes

    - name: Display cluster status
      debug:
        var: cluster_status.stdout_lines

    - name: Get kubeadm join command
      shell: kubeadm token create --print-join-command
      register: join_command
      changed_when: false

    - name: Set join command fact for workers
      set_fact:
        worker_join_cmd: "{{ join_command.stdout }}"
      delegate_to: localhost
      run_once: true

- name: Join worker nodes to the cluster
  hosts: workers
  become: yes
  tasks:
    - name: Join the node to the cluster
      shell: "{{ hostvars[groups['master'][0]].worker_join_cmd }} --ignore-preflight-errors=all"
      args:
        creates: /etc/kubernetes/kubelet.conf

- name: Deploy Jenkins in Kubernetes using Helm
  hosts: master
  become: yes
  tasks:
    - name: Uninstall existing Jenkins release if present
      shell: |
        helm uninstall jenkins --namespace jenkins || true
      environment:
        KUBECONFIG: /home/azureuser/.kube/config
      args:
        executable: /bin/bash

    - name: Add local-path StorageClass for dynamic PVCs
      shell: |
        kubectl apply -f https://raw.githubusercontent.com/rancher/local-path-provisioner/master/deploy/local-path-storage.yaml
        kubectl patch storageclass local-path -p '{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"true"}}}'
      environment:
        KUBECONFIG: /home/azureuser/.kube/config
      args:
        creates: /tmp/local-path-storageclass-applied

    - name: Wait for local-path provisioner pods to be ready
      shell: |
        kubectl wait --for=condition=Ready pod -l app=local-path-provisioner -n local-path-storage --timeout=120s
      environment:
        KUBECONFIG: /home/azureuser/.kube/config
      register: local_path_ready
      failed_when: local_path_ready.rc != 0

    - name: Add Jenkins Helm repo
      command: helm repo add jenkins https://charts.jenkins.io
      environment:
        KUBECONFIG: /home/azureuser/.kube/config
      args:
        creates: /root/.cache/helm/repository/jenkins-index.yaml

    - name: Update Helm repos
      command: helm repo update
      environment:
        KUBECONFIG: /home/azureuser/.kube/config

    - name: Ensure jenkins namespace exists
      shell: |
        kubectl get namespace jenkins || kubectl create namespace jenkins
      environment:
        KUBECONFIG: /home/azureuser/.kube/config
      register: jenkins_ns
      ignore_errors: yes

    - name: Ensure Jenkins PVC exists (idempotent)
      shell: |
        cat <<'EOF' | kubectl apply -f -
        apiVersion: v1
        kind: PersistentVolumeClaim
        metadata:
          name: jenkins
          namespace: jenkins
        spec:
          accessModes:
            - ReadWriteOnce
          resources:
            requests:
              storage: 8Gi
          storageClassName: local-path
        EOF
      environment:
        KUBECONFIG: /home/azureuser/.kube/config
      args:
        executable: /bin/bash

    - name: Ensure PVC has Helm ownership labels/annotations so Helm can adopt it
      shell: |
        if kubectl get pvc jenkins -n jenkins >/dev/null 2>&1; then
          kubectl label pvc jenkins -n jenkins app.kubernetes.io/managed-by=Helm --overwrite || true
          kubectl annotate pvc jenkins -n jenkins meta.helm.sh/release-name=jenkins --overwrite || true
          kubectl annotate pvc jenkins -n jenkins meta.helm.sh/release-namespace=jenkins --overwrite || true
        else
          echo "PVC jenkins does not exist yet; skipping labels/annotations"
        fi
      environment:
        KUBECONFIG: /home/azureuser/.kube/config
      args:
        executable: /bin/bash

    - name: Install Jenkins via Helm without problematic plugins to avoid DNS/TLS issues
      command: >
        helm install jenkins jenkins/jenkins
        --namespace jenkins
        --set controller.persistence.enabled=true
        --set controller.persistence.storageClass=local-path
        --set controller.persistence.size=8Gi
        --set controller.installPlugins=""
        --set controller.initializeOnce=true
        --set controller.agent.image=jenkins/inbound-agent
        --set controller.agent.tag=latest
        --set controller.agent.resources.requests.cpu=100m
        --set controller.agent.resources.requests.memory=256Mi
        --set controller.agent.resources.limits.cpu=500m
        --set controller.agent.resources.limits.memory=512Mi
        --set controller.agent.enabled=true
        --set controller.agent.customJenkinsLabels=k8s-agent
        --set controller.agent.podRetention=Never
        --set controller.dnsPolicy=ClusterFirst
        --set controller.dnsConfig.nameservers[0]=168.63.129.16
        --set controller.dnsConfig.nameservers[1]=8.8.8.8
        --set controller.dnsConfig.searches[0]=jenkins.svc.cluster.local
        --set controller.dnsConfig.searches[1]=svc.cluster.local
        --set controller.dnsConfig.searches[2]=cluster.local
        --set controller.dnsConfig.options[0].name=ndots
        --set controller.dnsConfig.options[0].value=2
        --set controller.dnsConfig.options[1].name=edns0
        --set controller.hostNetwork=false
        --set controller.serviceType=ClusterIP
        --set controller.javaOpts="-Dhudson.model.DownloadService.noSignatureCheck=true -Dhudson.plugins.git.GitSCM.ALLOW_LOCAL_CHECKOUT=true -Djenkins.install.runSetupWizard=false"
      environment:
        KUBECONFIG: /home/azureuser/.kube/config
      args:
        creates: /tmp/jenkins-helm-installed

    - name: Create Jenkins ConfigMap for plugin installation workaround
      shell: |
        kubectl apply -f - <<EOF
        apiVersion: v1
        kind: ConfigMap
        metadata:
          name: jenkins-plugin-config
          namespace: jenkins
        data:
          plugins.txt: |
            # Minimal essential plugins that should be available offline
            workflow-aggregator:596.v8c21c963d92d
            kubernetes:4246.v5a_12b_1fe120a_
            git:5.4.1
            configuration-as-code:1810.v9b_c30a_249a_4c
        EOF
      environment:
        KUBECONFIG: /home/azureuser/.kube/config
      ignore_errors: yes

    - name: Wait for Jenkins to be ready
      shell: |
        kubectl rollout status statefulSet/jenkins -n jenkins --timeout=600s
      environment:
        KUBECONFIG: /home/azureuser/.kube/config
      register: rollout_status
      retries: 15
      delay: 30
      until: rollout_status.rc == 0

    - name: Verify Jenkins pod is running without init container failures
      shell: |
        echo "=== Jenkins Pod Status ==="
        kubectl get pods -n jenkins
        echo "=== Jenkins Pod Events ==="
        kubectl get events -n jenkins --sort-by='.lastTimestamp' | tail -10
      environment:
        KUBECONFIG: /home/azureuser/.kube/config
      register: jenkins_status_check
      ignore_errors: yes

    - name: Display Jenkins status
      debug:
        var: jenkins_status_check.stdout_lines

    - name: Test DNS resolution from within Jenkins namespace
      shell: |
        kubectl run dns-test-jenkins --image=busybox:1.28 --rm -it --restart=Never -n jenkins --command -- nslookup mirrors.updates.jenkins.io || true
        kubectl run dns-test-jenkins2 --image=busybox:1.28 --rm -it --restart=Never -n jenkins --command -- nslookup updates.jenkins.io || true
      environment:
        KUBECONFIG: /home/azureuser/.kube/config
      register: jenkins_dns_test
      ignore_errors: yes

    - name: Display Jenkins DNS test results
      debug:
        var: jenkins_dns_test.stdout_lines

    - name: Get Jenkins admin password if deployment succeeded
      shell: |
        if kubectl get secret jenkins -n jenkins >/dev/null 2>&1; then
          echo "Jenkins admin password:"
          kubectl get secret jenkins -n jenkins -o jsonpath="{.data.jenkins-admin-password}" | base64 --decode
          echo ""
          echo "Access Jenkins with: kubectl port-forward svc/jenkins 8080:8080 -n jenkins"
        else
          echo "Jenkins secret not found - deployment may have failed"
        fi
      environment:
        KUBECONFIG: /home/azureuser/.kube/config
      register: jenkins_credentials
      ignore_errors: yes

    - name: Display Jenkins access information
      debug:
        var: jenkins_credentials.stdout_lines

    - name: Configure Jenkins for CI/CD pipeline
      shell: |
        # Create a ConfigMap with Jenkins pipeline configuration
        kubectl apply -f - <<EOF
        apiVersion: v1
        kind: ConfigMap
        metadata:
          name: jenkins-pipeline-config
          namespace: jenkins
        data:
          pipeline-job.xml: |
            <?xml version='1.1' encoding='UTF-8'?>
            <flow-definition plugin="workflow-job@2.46">
              <actions/>
              <description>Python REST API CI/CD Pipeline</description>
              <keepDependencies>false</keepDependencies>
              <properties>
                <org.jenkinsci.plugins.workflow.job.properties.PipelineTriggersJobProperty>
                  <triggers>
                    <hudson.triggers.SCMTrigger>
                      <spec>H/5 * * * *</spec>
                      <ignorePostCommitHooks>false</ignorePostCommitHooks>
                    </hudson.triggers.SCMTrigger>
                  </triggers>
                </org.jenkinsci.plugins.workflow.job.properties.PipelineTriggersJobProperty>
              </properties>
              <definition class="org.jenkinsci.plugins.workflow.cps.CpsScmFlowDefinition" plugin="workflow-cps@2.94">
                <scm class="hudson.plugins.git.GitSCM" plugin="git@4.8.3">
                  <configVersion>2</configVersion>
                  <userRemoteConfigs>
                    <hudson.plugins.git.UserRemoteConfig>
                      <url>https://github.com/your-username/python-rest-api.git</url>
                    </hudson.plugins.git.UserRemoteConfig>
                  </userRemoteConfigs>
                  <branches>
                    <hudson.plugins.git.BranchSpec>
                      <name>*/main</name>
                    </hudson.plugins.git.BranchSpec>
                  </branches>
                  <doGenerateSubmoduleConfigurations>false</doGenerateSubmoduleConfigurations>
                  <submoduleCfg class="list"/>
                  <extensions/>
                </scm>
                <scriptPath>Jenkinsfile</scriptPath>
                <lightweight>true</lightweight>
              </definition>
              <triggers/>
              <disabled>false</disabled>
            </flow-definition>
        EOF
      environment:
        KUBECONFIG: /home/azureuser/.kube/config
      ignore_errors: yes

    - name: Create RBAC for Jenkins to manage deployments
      shell: |
        kubectl apply -f - <<EOF
        apiVersion: rbac.authorization.k8s.io/v1
        kind: ClusterRole
        metadata:
          name: jenkins-deploy
        rules:
        - apiGroups: [""]
          resources: ["pods", "services", "configmaps", "secrets"]
          verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
        - apiGroups: ["apps"]
          resources: ["deployments", "replicasets"]
          verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
        - apiGroups: ["networking.k8s.io"]
          resources: ["ingresses"]
          verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
        ---
        apiVersion: rbac.authorization.k8s.io/v1
        kind: ClusterRoleBinding
        metadata:
          name: jenkins-deploy
        roleRef:
          apiGroup: rbac.authorization.k8s.io
          kind: ClusterRole
          name: jenkins-deploy
        subjects:
        - kind: ServiceAccount
          name: jenkins
          namespace: jenkins
        EOF
      environment:
        KUBECONFIG: /home/azureuser/.kube/config
      ignore_errors: yes

- name: Deploy Python REST API in Kubernetes using Helm
  hosts: master
  become: yes
  tasks:
    - name: Create namespace for API
      command: kubectl create namespace python-api
      environment:
        KUBECONFIG: /home/azureuser/.kube/config
      args:
        creates: /tmp/python-api-namespace-created
      register: api_ns
      failed_when: false

    - name: Copy k8s-deploy.yml to master node
      copy:
        src: k8s-deploy.yml
        dest: /home/azureuser/k8s-deploy.yml
        owner: azureuser
        group: azureuser
        mode: '0644'

    - name: Deploy Python REST API via kubectl
      shell: |
        kubectl apply -f /home/azureuser/k8s-deploy.yml
      environment:
        KUBECONFIG: /home/azureuser/.kube/config
      register: python_api_deploy
      retries: 3
      delay: 10

    - name: Wait for Python REST API deployment to be ready
      shell: |
        kubectl rollout status deployment/python-rest-api -n python-api --timeout=300s
      environment:
        KUBECONFIG: /home/azureuser/.kube/config
      register: api_rollout_status
      retries: 10
      delay: 30
      until: api_rollout_status.rc == 0

- name: Deploy NGINX ingress controller in Kubernetes using Helm
  hosts: master
  become: yes
  tasks:
    - name: Add NGINX ingress Helm repo
      command: helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
      environment:
        KUBECONFIG: /home/azureuser/.kube/config

    - name: Update Helm repos
      command: helm repo update
      environment:
        KUBECONFIG: /home/azureuser/.kube/config

    - name: Install NGINX ingress controller
      command: >
        helm install ingress-nginx ingress-nginx/ingress-nginx
        --namespace ingress-nginx --create-namespace
      environment:
        KUBECONFIG: /home/azureuser/.kube/config

- name: Install cert-manager in Kubernetes using Helm
  hosts: master
  become: yes
  tasks:
    - name: Add Jetstack Helm repo
      command: helm repo add jetstack https://charts.jetstack.io
      environment:
        KUBECONFIG: /home/azureuser/.kube/config

    - name: Update Helm repos
      command: helm repo update
      environment:
        KUBECONFIG: /home/azureuser/.kube/config

    - name: Install cert-manager
      command: >
        helm install cert-manager jetstack/cert-manager
        --namespace cert-manager --create-namespace
        --set installCRDs=true
        --wait --timeout=10m
      environment:
        KUBECONFIG: /home/azureuser/.kube/config

    - name: Wait for cert-manager webhook to be ready
      shell: |
        kubectl wait --for=condition=Available deployment/cert-manager-webhook -n cert-manager --timeout=300s
      environment:
        KUBECONFIG: /home/azureuser/.kube/config
      ignore_errors: yes

    - name: Configure cert-manager with Azure DNS
      shell: |
        kubectl patch deployment cert-manager -n cert-manager -p '{
          "spec": {
            "template": {
              "spec": {
                "dnsPolicy": "ClusterFirst",
                "dnsConfig": {
                  "nameservers": ["168.63.129.16", "8.8.8.8"],
                  "searches": ["cert-manager.svc.cluster.local", "svc.cluster.local", "cluster.local"],
                  "options": [
                    {"name": "ndots", "value": "2"},
                    {"name": "edns0"}
                  ]
                }
              }
            }
          }
        }'
      environment:
        KUBECONFIG: /home/azureuser/.kube/config
      ignore_errors: yes

    - name: Wait for cert-manager to restart with DNS configuration
      shell: |
        kubectl rollout status deployment/cert-manager -n cert-manager --timeout=300s
      environment:
        KUBECONFIG: /home/azureuser/.kube/config

    - name: Create ClusterIssuer for Let's Encrypt
      shell: |
        # Wait for webhook to be fully ready, then create ClusterIssuer
        sleep 30
        kubectl apply --validate=false -f - <<EOF
        apiVersion: cert-manager.io/v1
        kind: ClusterIssuer
        metadata:
          name: letsencrypt-prod
        spec:
          acme:
            server: https://acme-v02.api.letsencrypt.org/directory
            email: Klodian.kuka@gmail.com
            privateKeySecretRef:
              name: letsencrypt-prod
            solvers:
            - http01:
                ingress:
                  class: nginx
        EOF
      environment:
        KUBECONFIG: /home/azureuser/.kube/config
      ignore_errors: yes

